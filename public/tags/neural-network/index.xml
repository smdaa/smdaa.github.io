<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Neural Network on smdaa</title>
    <link>http://localhost:1313/tags/neural-network/</link>
    <description>Recent content in Neural Network on smdaa</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <atom:link href="http://localhost:1313/tags/neural-network/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Building an Autograd Library from Scratch in C for Simple Neural Networks</title>
      <link>http://localhost:1313/post/building-an-autograd-library-from-scratch-in-c-for-simple-neural-networks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/building-an-autograd-library-from-scratch-in-c-for-simple-neural-networks/</guid>
      <description>&lt;h2 id=&#34;table-of-contents&#34;&gt;Table of contents&lt;/h2&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Autograd is a fundamental component in machine learning frameworks, enabling the automatic computation of gradients for training neural networks. This article will walk you through my journey of writing an Autograd library from scratch (no third-party libraries) in pure C.&lt;/p&gt;&#xA;&lt;p&gt;The source code is hosted in this &lt;a href=&#34;https://github.com/smdaa/teeny-autograd-c&#34;&gt;repository&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;neural-networks-a-brief-overview&#34;&gt;Neural Networks: A Brief Overview&lt;/h2&gt;&#xA;&lt;p&gt;At its core, a neural network consists of neurons organized in layers. Each neuron receives input from the previous layer, processes it using a weighted sum, applies an activation function, and passes the output to the next layer.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
